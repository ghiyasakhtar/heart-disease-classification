# -*- coding: utf-8 -*-
"""[Predictive Analytics] Proyek Machine Learning_Ghiyas Akhtar Razi Ramadhan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jWLCliLQi0nKYicUWCk1GDS73dNJW6dE

# **Dicoding Predictive Analytics Project**: Prediksi Risiko Serangan Jantung

## **Instalasi dan Import Library**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

import matplotlib.pyplot as plt

import joblib

"""## **Memuat Dataset**"""

# Load dataset
df = pd.read_csv("dataset.csv")

"""## **Eksplorasi Awal Dataset & Data Understanding**

### **Eksplorasi Awal Dataset**
"""

# Lihat 5 baris pertama
print("Preview dataset: ")
display(df.head())

# Info tipe data & null check
print("\nInformasi kolom:")
df.info()

# Cek missing values
print("\nMissing values tiap kolom:")
print(df.isnull().sum())

# Statistik deskriptif
print("\nStatistik deskriptif:")
display(df.describe())

"""### **Data Understanding**

Dataset ini berisi 1025 data pasien dengan berbagai fitur medis yang berkaitan dengan risiko penyakit jantung. Tujuan dari proyek ini adalah memprediksi apakah seseorang berisiko terkena penyakit jantung (1) atau tidak (0), yang ditunjukkan oleh kolom `target`.

### Penjelasan fitur:
- **age**: usia pasien
- **sex**: jenis kelamin (1 = pria, 0 = wanita)
- **cp**: tipe nyeri dada (0–3)
- **trestbps**: tekanan darah saat istirahat (mm Hg)
- **chol**: kadar kolesterol dalam darah (mg/dl)
- **fbs**: gula darah > 120 mg/dl (1 = ya, 0 = tidak)
- **restecg**: hasil EKG saat istirahat (0–2)
- **thalach**: detak jantung maksimal yang dicapai
- **exang**: angina akibat olahraga (1 = ya, 0 = tidak)
- **oldpeak**: depresi ST akibat olahraga
- **slope**: kemiringan segmen ST (0–2)
- **ca**: jumlah pembuluh darah utama (0–3)
- **thal**: nilai thalassemia (1 = normal, 2 = fixed defect, 3 = reversible defect)
- **target**: 1 = berisiko jantung, 0 = tidak

Dataset ini tidak mengandung missing value, sehingga bisa langsung dilanjutkan ke tahap berikutnya.

## **Exploratory Data Analysis (EDA)**
"""

# Set style
sns.set(style="whitegrid")

"""Distribusi Target"""

plt.figure(figsize=(6,4))
sns.countplot(x='target', data=df, palette='Set2')
plt.title("Distribusi Target (0 = Tidak Risiko, 1 = Risiko)")
plt.xlabel("Target")
plt.ylabel("Jumlah")
plt.show()

"""Distribusi Usia"""

plt.figure(figsize=(8,4))
sns.histplot(df['age'], bins=20, kde=True, color='skyblue')
plt.title("Distribusi Usia Pasien")
plt.xlabel("Usia")
plt.ylabel("Jumlah")
plt.show()

"""Korelasi antar fitur (Heatmap)"""

plt.figure(figsize=(12,10))
corr = df.corr()
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title("Heatmap Korelasi Antar Fitur")
plt.show()

"""Fitur vs Target"""

# Nyeri dada vs target
plt.figure(figsize=(6,4))
sns.countplot(x='cp', hue='target', data=df, palette='Set1')
plt.title("Tipe Nyeri Dada vs Risiko Penyakit Jantung")
plt.xlabel("Tipe Nyeri Dada (cp)")
plt.ylabel("Jumlah")
plt.legend(title="Target", loc="upper right")
plt.show()

"""Distribusi target menunjukkan bahwa dataset relatif seimbang antara pasien dengan risiko penyakit jantung (1) dan yang tidak (0). Usia pasien berkisar dari sekitar 29 hingga 77 tahun, dengan konsentrasi di usia 50-an.

Fitur `cp` (nyeri dada) memiliki korelasi positif kuat dengan `target`, yang berarti jenis nyeri dada tertentu cenderung menandakan risiko jantung. Fitur `thalach` (detak jantung maksimal) juga menunjukkan korelasi signifikan.

Visualisasi heatmap menunjukkan fitur yang paling berkorelasi dengan `target` adalah:
- cp (nyeri dada)
- thalach (detak jantung maksimum)
- exang (angina karena olahraga)
- oldpeak (ST depression)

## **Data Preparation and Preprocessing**

Memisahkan fitur (X) dan target (y)
"""

X = df.drop('target', axis=1)
y = df['target']

"""Split Data: Training & Testing"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Training size: {X_train.shape[0]} | Testing size: {X_test.shape[0]}")

"""Standarisasi Fitur (Numerik)"""

# Inisialisasi scaler
scaler = StandardScaler()

# Fit-transform ke X_train, transform ke X_test
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""**Data Preparation**

Sebelum melatih model, data dibagi menjadi fitur (X) dan target (y). Kemudian dilakukan pembagian data menjadi training dan testing dengan rasio 80:20, menggunakan `stratify` untuk menjaga distribusi target.

Selanjutnya, dilakukan standarisasi fitur numerik menggunakan `StandardScaler` dari Scikit-Learn agar model dapat bekerja lebih baik, terutama untuk algoritma berbasis jarak seperti SVM dan KNN.

## **Modelling**

### **Baseline Model - Logistic Regression**
"""

# Inisialisasi model
lr_model = LogisticRegression(max_iter=1000, random_state=42)

# Training
lr_model.fit(X_train_scaled, y_train)

# Prediksi
y_pred_lr = lr_model.predict(X_test_scaled)

# Evaluasi
print("Akurasi:", accuracy_score(y_test, y_pred_lr))
print("\nClassification Report:\n", classification_report(y_test, y_pred_lr))
print("\nConfusion Matrix:")
sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

"""Model Lain untuk Dibandingkan (Random Forest, SVM, & KKN)"""

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_scaled, y_train)
rf_pred = rf.predict(X_test_scaled)

# SVM
svm = SVC(random_state=42)
svm.fit(X_train_scaled, y_train)
svm_pred = svm.predict(X_test_scaled)

# KNN
knn = KNeighborsClassifier()
knn.fit(X_train_scaled, y_train)
knn_pred = knn.predict(X_test_scaled)

# Evaluasi semua
models = {
    "Logistic Regression": y_pred_lr,
    "Random Forest": rf_pred,
    "SVM": svm_pred,
    "KNN": knn_pred
}

for name, pred in models.items():
    print(f"\nModel: {name}")
    print("Accuracy:", accuracy_score(y_test, pred))

"""**Modeling & Evaluation**

Model baseline menggunakan Logistic Regression memberikan akurasi awal yang cukup baik. Selain itu, beberapa model lain juga diuji untuk dibandingkan:

- **Random Forest**: model ensemble berbasis pohon keputusan
- **Support Vector Machine (SVM)**: cocok untuk data dengan margin yang jelas
- **K-Nearest Neighbors (KNN)**: berbasis kemiripan jarak antar titik

Evaluasi dilakukan menggunakan akurasi, classification report, dan confusion matrix. Model dengan performa terbaik akan digunakan untuk deployment dan kesimpulan akhir.

## **Evaluasi Lanjutan & Pemilihan Model Terbaik**

Evaluasi Semua Model
"""

# Evaluasi ulang model-model
for name, pred in models.items():
    print("="*40)
    print(f"Model: {name}")
    print("Accuracy :", accuracy_score(y_test, pred))
    print(classification_report(y_test, pred))

"""Visualisasi Akurasi Semua Model"""

accuracies = {
    "Logistic Regression": accuracy_score(y_test, y_pred_lr),
    "Random Forest": accuracy_score(y_test, rf_pred),
    "SVM": accuracy_score(y_test, svm_pred),
    "KNN": accuracy_score(y_test, knn_pred),
}

plt.figure(figsize=(8,4))
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette="Set2")
plt.title("Perbandingan Akurasi Model")
plt.ylabel("Akurasi")
plt.ylim(0, 1)
plt.xticks()
plt.show()

"""### **Analisis Model**
| Model               | Akurasi  | Recall (positif) | F1-score (positif) | Catatan                                                    |
|---------------------|----------|------------------|--------------------|-------------------------------------------------------------|
| Logistic Regression | 0.81     | 0.91             | 0.83               | Baik dalam mendeteksi pasien berisiko (recall tinggi)       |
| **Random Forest**   | **1.00** | **1.00**         | **1.00**           | Terlalu sempurna → **indikasi overfitting** pada data test  |
| SVM                 | 0.93     | 0.94             | 0.93               | Sangat baik, balance di semua metrik                        |
| KNN                 | 0.86     | 0.86             | 0.87               | Baik tapi masih kalah dari SVM di semua metrik              |




### **Evaluasi Model**

Evaluasi model dilakukan menggunakan metrik akurasi, precision, recall, dan f1-score. Dari hasil evaluasi:

- Model dengan akurasi tertinggi adalah **Random Forest**
- Model dengan keseimbangan metrik terbaik adalah **SVM (Support Vector Machine)**

Pemilihan model terbaik mempertimbangkan tidak hanya akurasi, tetapi juga *recall* dan *f1-score*, terutama karena kasus penyakit jantung lebih penting meminimalkan kesalahan deteksi positif.

## **Menyimpan Model & Scaler**
"""

# Simpan model SVM dan scaler
joblib.dump(svm, 'svm_model.pkl')
joblib.dump(scaler, 'scaler.pkl')

"""## **Kesimpulan Proyek**

Pada proyek ini, telah dibangun sebuah model machine learning untuk memprediksi risiko penyakit jantung berdasarkan data medis pasien. Proses dimulai dari eksplorasi data, pembersihan, transformasi fitur, hingga pelatihan dan evaluasi beberapa model.

Model terbaik yang dipilih adalah **Support Vector Machine (SVM)** dengan performa sebagai berikut:
- Akurasi: 93%
- Recall positif: 94%
- F1-score positif: 93%

Model ini menunjukkan performa yang tinggi dan seimbang dalam mendeteksi pasien berisiko penyakit jantung, dan tidak menunjukkan overfitting seperti model Random Forest.

"""